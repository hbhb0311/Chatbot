# 다중 분류(Multi-class Classification) 1 - 개념



<br>



# 다중 분류

다중 분류 : 몇 가지 정해진 후보 가운데 하나를 선택해 답하는 문제

이진 판단에서 처럼 각 후보 항목에 대한 로짓값 추정(로그 척도의 상대적 추천 강도)

→ 퍼셉트론 하나가 후보 하나에 대한 로짓값 출력

따라서 다중 분류 후보 수 만큼의 퍼셉트론이 필요



<br>



![Untitled](https://user-images.githubusercontent.com/78071068/136334905-7c44583e-440c-4e9c-8d0e-973ab042da74.png)



⇒ 우승 확률을 구하는 방법 

1. 각 로짓값을 구한다
2. 각 로짓값에 대한 확률을 계산한다



<br>



```python
team1 = np.exp(2.0)
team2 = np.exp(1.0)
team3 = np.exp(1.2)
team4 = np.exp(0.7)
total = team1 + team2 + team3 + team4 

print('로짓값')
print('team1 - {:5.3f}'.format(team1))
print('team2 - {:5.3f}'.format(team2))
print('team3 - {:5.3f}'.format(team3))
print('team4 - {:5.3f}'.format(team4))

print('')
print('')

print('확률분포')
print('team1 - {:5.3f}'.format(team1/total))
print('team2 - {:5.3f}'.format(team2/total))
print('team3 - {:5.3f}'.format(team3/total))
print('team4 - {:5.3f}'.format(team4/total))
```

![_2021-01-29__6 04 37](https://user-images.githubusercontent.com/78071068/136335052-9f0ab5b0-8b4a-4822-b6d3-25d2cda6e8dc.png)



<br>



하지만! 

굳이 확률값으로 변환하지 않아도, 어떤 팀이 큰 값을 가지는지 확인 가능한데, 왜 확률값 처리를 할까?

1. 모델의 학습을 위해

확률분포 + 교차 엔트로피 

→ 신경망이 추정한 확률 분포와 정답이 나타내는 확률 분포 사이의 교차 엔트로피 구할 수 있음

→ 이 교차 엔트로피를 손실함수로 학습을 수행하면, 신경망이 추정한 확률 분포를 정답에 근접시킬 수  있음



<br>



⇒ 따라서 다수의 후보 항목들에 대해 로짓값 벡터를 확률 분포 벡터로 변환해주는 소프트맥스(softmax)

   + 이렇게 구해진 확률 분포 VS 정답에 나타난 확률 분포 → 교차 엔트로피를 계산

⇒ 소프트맥스 교차 엔트로피(softmax cross entropy) 필요



<br>

<br>



2. 연구자가 쉽게 결과를 확인하기 위해 





# 활성화함수 : 소프트맥스(softmax)

![Untitled 1](https://user-images.githubusercontent.com/78071068/136335118-a4c98fc7-6b97-46d4-b5eb-501ec47c12dd.png)

→ 소프트맥스 함수 : 로짓값 벡터를 확률 분포 벡터로 변환해주는 비선형 활성화 함수



<br>



![Untitled 2](https://user-images.githubusercontent.com/78071068/136335482-b7f73366-f7eb-4f77-8bf7-6b8d5b4b7abe.png)



소프트맥스 함수 도출 과정



<br>



![Untitled 3](https://user-images.githubusercontent.com/78071068/136335532-33ee7a11-9197-4afc-80fe-3825daae8ef2.png)

<br>



소프트맥스 함수 일반식

→ 하지만, 오버플로우 문제 발생 가능

x가 엄청나게 큰 값 → inf로 발산 (overflow 발생)

x가 엄청나게 작은 값 → 분모가 0으로 수렴 → 0으로 나눗셈을 진행하는 상황 발생

→ 이를 해결하기 위한 과정 : x값 중 가장 큰 값으로 모든 지수 나눠줌



<br>



![Untitled 4](https://user-images.githubusercontent.com/78071068/136335670-aa584528-24c8-435c-ab6d-9b637dbc607c.png)

→ 최종적으로 나온 식

![Untitled 5](https://user-images.githubusercontent.com/78071068/136335711-300f1000-13a7-44be-af64-bdab23909cb4.png)

[logit, sigmoid, softmax의 관계](https://opentutorials.org/module/3653/22995)



<br>



## 소프트맥스 편미분

[소프트맥스 편미분, 교차 엔트로피 편미분 과정](https://opentutorials.org/module/3653/22995)



![KakaoTalk_Photo_2021-01-30-00-40-46](https://user-images.githubusercontent.com/78071068/136336219-1e8b1cee-e5ac-470d-9f6e-40104fa80887.jpeg)

![KakaoTalk_Photo_2021-01-30-00-40-52](https://user-images.githubusercontent.com/78071068/136335999-9f71196b-c1ae-48ed-91a5-662b0497e57b.jpeg)



<br>



## 소프트맥스 교차엔트로피



![Untitled 6](https://user-images.githubusercontent.com/78071068/136335847-fe72a84d-577f-4119-beb7-5d2d594e0c0f.png)

→ $q_i$ 가 0에 근접한 아주 작은 값일 때, $log q_i$ 는 -inf 로 향해 값이 폭주하는 현상을 불러옴

따라서 아주 작은 값인 $\varepsilon$ 를 더해줌



<br>



### 소프트맥스 교차엔트로피 편미분



![KakaoTalk_Photo_2021-01-30-00-40-54](https://user-images.githubusercontent.com/78071068/136335991-a4f443f7-14d9-4803-996a-65e4feeee03b.jpeg)